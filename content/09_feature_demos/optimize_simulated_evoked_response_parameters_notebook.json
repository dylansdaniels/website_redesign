{
    "full_executed": false,
    "optimize_simulated_evoked_response_parameters_notebook.ipynb": {
        "9.8: Optimize simulated evoked response parameters": {
            "level": 1,
            "html": "<div class='markdown-cell'>\n    <h1>9.8: Optimize simulated evoked response parameters</h1>\n<p>This example demonstrates how to optimize the parameters of the model\nsimulation to match an experimental dipole waveform.</p>\n\n</div>\n<div class='code-cell'>\n    <code class='language-python'>\n        # Authors: Carolina Fernandez <cxf418@miami.edu>\n#          Nick Tolley <nicholas_tolley@brown.edu>\n#          Ryan Thorpe <ryan_thorpe@brown.edu>\n#          Mainak Jas <mjas@mgh.harvard.edu>\n\nimport os.path as op\n\nimport matplotlib.pyplot as plt\n    </code>\n</div>\n<div class='markdown-cell'>\n    <p>Let us import <code>hnn_core</code></p>\n\n</div>\n<div class='code-cell'>\n    <code class='language-python'>\n        import hnn_core\nfrom hnn_core import (MPIBackend, jones_2009_model, simulate_dipole,\n                      read_dipole)\n\nhnn_core_root = op.join(op.dirname(hnn_core.__file__))\n\n# The number of cores may need modifying depending on your current machine.\nn_procs = 10\n    </code>\n</div>\n<div class='markdown-cell'>\n    <p>First, we will load experimental data into a <a\nhref=\"https://jonescompneurolab.github.io/hnn-core/stable/generated/hnn_core.dipole.Dipole.html#hnn_core.dipole.Dipole\">Dipole\nobject</a> using <a\nhref=\"https://jonescompneurolab.github.io/hnn-core/stable/generated/hnn_core.read_dipole.html#hnn_core.read_dipole\">read_dipole</a>.\nThis is a different experiment than the one to which the base parameters\nwere tuned. So, the initial RMSE will be large, giving the optimization\nprocedure a lot to work with.</p>\n\n</div>\n<div class='code-cell'>\n    <code class='language-python'>\n        from urllib.request import urlretrieve\n\ndata_url = ('https://raw.githubusercontent.com/jonescompneurolab/hnn/master/'\n            'data/MEG_detection_data/S1_SupraT.txt')\nurlretrieve(data_url, 'S1_SupraT.txt')\nexp_dpl = read_dipole('S1_SupraT.txt')\n    </code>\n</div>\n<div class='markdown-cell'>\n    <p>Let\u2019s then simulate the dipole with some initial parameters.</p>\n\n</div>\n<div class='code-cell'>\n    <code class='language-python'>\n        tstop = exp_dpl.times[-1]\nscale_factor = 3000\nsmooth_window_len = 30\n\nnet_init = jones_2009_model()\n\n# Proximal 1\nweights_ampa_p1 = {'L2_basket': 0.2913, 'L2_pyramidal': 0.9337,\n                   'L5_basket': 0.1951, 'L5_pyramidal': 0.3602}\nweights_nmda_p1 = {'L2_basket': 0.9240, 'L2_pyramidal': 0.0845,\n                   'L5_basket': 0.5849, 'L5_pyramidal': 0.65105}\nsynaptic_delays_p = {'L2_basket': 0.1, 'L2_pyramidal': 0.1,\n                     'L5_basket': 1., 'L5_pyramidal': 1.}\nnet_init.add_evoked_drive('evprox1',\n                          mu=5.6813,\n                          sigma=20.3969,\n                          numspikes=1,\n                          location='proximal',\n                          weights_ampa=weights_ampa_p1,\n                          weights_nmda=weights_nmda_p1,\n                          synaptic_delays=synaptic_delays_p)\n\n# Distal\nweights_ampa_d1 = {'L2_basket': 0.8037, 'L2_pyramidal': 0.5738,\n                   'L5_pyramidal': 0.3626}\nweights_nmda_d1 = {'L2_basket': 0.2492, 'L2_pyramidal': 0.6183,\n                   'L5_pyramidal': 0.1121}\nsynaptic_delays_d1 = {'L2_basket': 0.1, 'L2_pyramidal': 0.1,\n                      'L5_pyramidal': 0.1}\nnet_init.add_evoked_drive('evdist1',\n                          mu=58.6539,\n                          sigma=5.5810,\n                          numspikes=1,\n                          location='distal',\n                          weights_ampa=weights_ampa_d1,\n                          weights_nmda=weights_nmda_d1,\n                          synaptic_delays=synaptic_delays_d1)\n\n# Proximal 2\nweights_ampa_p2 = {'L2_basket': 0.01, 'L2_pyramidal': 0.01, 'L5_basket': 0.01,\n                   'L5_pyramidal': 0.01}\nweights_nmda_p2 = {'L2_basket': 0.01, 'L2_pyramidal': 0.01, 'L5_basket': 0.01,\n                   'L5_pyramidal': 0.01}\nnet_init.add_evoked_drive('evprox2',\n                          mu=80,\n                          sigma=1,\n                          numspikes=1,\n                          location='proximal',\n                          weights_ampa=weights_ampa_p2,\n                          weights_nmda=weights_nmda_p2,\n                          synaptic_delays=synaptic_delays_p)\n\nwith MPIBackend(n_procs=n_procs, mpi_cmd='mpiexec'):\n    init_dpl = simulate_dipole(net_init, tstop=tstop, n_trials=1)[0]\ninit_dpl.scale(scale_factor)\ninit_dpl.smooth(smooth_window_len)\n    </code>\n</div>\n<div class='markdown-cell'>\n    <p>Now we start the optimization!</p>\n<p>First, we define a function that will tell the optimization routine\nhow to modify the network drive parameters. The function will take in\nthe Network object with no attached drives, and a dictionary of the\nparameters we wish to optimize.</p>\n\n</div>\n<div class='code-cell'>\n    <code class='language-python'>\n        def set_params(net, params):\n\n    # Proximal 1\n    net.add_evoked_drive('evprox1',\n                         mu=5.6813,\n                         sigma=20.3969,\n                         numspikes=1,\n                         location='proximal',\n                         weights_ampa=weights_ampa_p1,\n                         weights_nmda=weights_nmda_p1,\n                         synaptic_delays=synaptic_delays_p)\n\n    # Distal\n    net.add_evoked_drive('evdist1',\n                         mu=58.6539,\n                         sigma=5.5810,\n                         numspikes=1,\n                         location='distal',\n                         weights_ampa=weights_ampa_d1,\n                         weights_nmda=weights_nmda_d1,\n                         synaptic_delays=synaptic_delays_d1)\n\n    # Proximal 2\n    weights_ampa_p2 = {'L2_basket':\n                       params['evprox2_ampa_L2_basket'],\n                       'L2_pyramidal':\n                       params['evprox2_ampa_L2_pyramidal'],\n                       'L5_basket':\n                       params['evprox2_ampa_L5_basket'],\n                       'L5_pyramidal':\n                       params['evprox2_ampa_L5_pyramidal']}\n    weights_nmda_p2 = {'L2_basket':\n                       params['evprox2_nmda_L2_basket'],\n                       'L2_pyramidal':\n                       params['evprox2_nmda_L2_pyramidal'],\n                       'L5_basket':\n                       params['evprox2_nmda_L5_basket'],\n                       'L5_pyramidal':\n                       params['evprox2_nmda_L5_pyramidal']}\n    net.add_evoked_drive('evprox2',\n                         mu=params['evprox2_mu'],\n                         sigma=params['evprox2_sigma'],\n                         numspikes=1,\n                         location='proximal',\n                         weights_ampa=weights_ampa_p2,\n                         weights_nmda=weights_nmda_p2,\n                         synaptic_delays=synaptic_delays_p)\n    </code>\n</div>\n<div class='markdown-cell'>\n    <p>Then, we define the constraints.</p>\n<p>The constraints must be a dictionary of tuples where the first value\nin each tuple is the lower bound and the second value is the upper bound\nfor the corresponding parameter.</p>\n<p>The following synaptic weight parameter ranges (units of\nmicro-siemens) were chosen so as to keep the model in physiologically\nrealistic regimes.</p>\n\n</div>\n<div class='code-cell'>\n    <code class='language-python'>\n        constraints = dict({'evprox2_ampa_L2_basket': (0.01, 1.),\n                    'evprox2_ampa_L2_pyramidal': (0.01, 1.),\n                    'evprox2_ampa_L5_basket': (0.01, 1.),\n                    'evprox2_ampa_L5_pyramidal': (0.01, 1.),\n                    'evprox2_nmda_L2_basket': (0.01, 1.),\n                    'evprox2_nmda_L2_pyramidal': (0.01, 1.),\n                    'evprox2_nmda_L5_basket': (0.01, 1.),\n                    'evprox2_nmda_L5_pyramidal': (0.01, 1.),\n                    'evprox2_mu': (100., 120.),\n                    'evprox2_sigma': (2., 30.)})\n    </code>\n</div>\n<div class='markdown-cell'>\n    <p>Now we define and fit the optimizer.</p>\n\n</div>\n<div class='code-cell'>\n    <code class='language-python'>\n        from hnn_core.optimization import Optimizer\n\nnet = jones_2009_model()\noptim = Optimizer(net, tstop=tstop, constraints=constraints,\n                  set_params=set_params)\nwith MPIBackend(n_procs=n_procs, mpi_cmd='mpiexec'):\n    optim.fit(target=exp_dpl, scale_factor=scale_factor,\n              smooth_window_len=smooth_window_len)\n    </code>\n</div>\n<div class='markdown-cell'>\n    <p>Finally, we can plot the experimental data alongside the\npost-optimization simulation dipole as well as the convergence plot.</p>\n\n</div>\n<div class='code-cell'>\n    <code class='language-python'>\n        with MPIBackend(n_procs=n_procs, mpi_cmd='mpiexec'):\n    opt_dpl = simulate_dipole(optim.net_, tstop=tstop, n_trials=1)[0]\nopt_dpl.scale(scale_factor)\nopt_dpl.smooth(smooth_window_len)\n\nfig, axes = plt.subplots(2, 1, sharex=True, figsize=(6, 6))\n\n# plot original\nexp_dpl.plot(ax=axes[0], layer='agg', show=False, color='tab:blue')\ninit_dpl.plot(ax=axes[0], layer='agg', show=False, color='tab:orange')\nopt_dpl.plot(ax=axes[0], layer='agg', show=False, color='tab:green')\naxes[0].legend(['experimental', 'initial', 'optimized'])\noptim.net_.cell_response.plot_spikes_hist(ax=axes[1], show=False)\nplt.show()\n    </code>\n</div>\n<div class='code-cell'>\n    <code class='language-python'>\n        fig1 = optim.plot_convergence(show=False)\nplt.show()\n    </code>\n</div>"
        }
    }
}