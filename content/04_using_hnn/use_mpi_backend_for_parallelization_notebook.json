{
    "full_executed": true,
    "use_mpi_backend_for_parallelization_notebook.ipynb": {
        "4.7: Use MPI backend for Parallelization": {
            "level": 1,
            "html": "<div class='markdown-cell'>\n    <h1>4.7: Use MPI backend for Parallelization</h1>\n<p>This example demonstrates how to use the MPI backend for simulating\ndipoles using HNN-core.</p>\n<p>The MPI backend allows running the simulation in parallel across\nneurons in the network even with a single trial. For this, you will need\nthe <a\nhref=\"https://github.com/jonescompneurolab/hnn-core?tab=readme-ov-file#installation\">MPI\nrelated software</a> installed. Note that if you want to simulate in\nparallel across trials, the Joblib backend allows this without the need\nto install and configure MPI.</p>\n\n</div>\n<div class='code-cell'>\n    <code class='language-python'>\n        # Authors: Mainak Jas <mjas@mgh.harvard.edu>\n#          Blake Caldwell <blake_caldwell@brown.edu>\n    </code>\n</div>\n<div class='markdown-cell'>\n    <p>Let us import <code>hnn_core</code></p>\n\n</div>\n<div class='code-cell'>\n    <code class='language-python'>\n        import os.path as op\n\nimport matplotlib.pyplot as plt\n\nimport hnn_core\nfrom hnn_core import simulate_dipole, jones_2009_model\n    </code>\n</div>\n<div class='markdown-cell'>\n    <p>Following our <a\nhref=\"https://dylansdaniels.github.io/website_redesign/content/06_alpha_beta/api.html\">Alpha\nexample</a>, we add a ~10 Hz \"bursty\" drive starting at 50 ms and\ncontinuing to the end of the simulation. Each burst consists of a pair\n(2) of spikes, spaced 10 ms apart. The occurrence of each burst is\njittered by a random, normally distributed amount (20 ms standard\ndeviation). We repeat the burst train 10 times, each time with unique\nrandomization.</p>\n\n</div>\n<div class='code-cell'>\n    <code class='language-python'>\n        net = jones_2009_model()\n\nweights_ampa = {'L2_pyramidal': 5.4e-5, 'L5_pyramidal': 5.4e-5}\nnet.add_bursty_drive(\n    'bursty', tstart=50., burst_rate=10, burst_std=20., numspikes=2,\n    spike_isi=10, n_drive_cells=10, location='distal',\n    weights_ampa=weights_ampa, event_seed=278)\n    </code>\n</div>\n<div class='markdown-cell'>\n    <p>Finally, to simulate we use the <a\nhref=\"https://jonescompneurolab.github.io/hnn-core/stable/generated/hnn_core.parallel_backends.MPIBackend.html#hnn_core.parallel_backends.MPIBackend\">MPIBackend</a>\nclass. This will start the simulation across the number of processors\n(cores) specified by <code>n_procs</code> using MPI. The\n<code>mpiexec</code> launcher is used from <code>openmpi</code>, which\nmust be installed on the system.</p>\n\n</div>\n<div class='code-cell'>\n    <code class='language-python'>\n        from hnn_core import MPIBackend\n\nwith MPIBackend(n_procs=2, mpi_cmd='mpiexec'):\n    dpls = simulate_dipole(net, tstop=310., n_trials=1)\n\ntrial_idx = 0\ndpls[trial_idx].plot(show=False)\nplt.show()\n    </code>\n</div>\n<div class='output-cell'><div class='output-label'>\n    Out:\n</div>\n    <div class='output-code'>\n        MPI will run 1 trial(s) sequentially by distributing network neurons over 2 processes.\n/opt/anaconda3/envs/hc12/bin/nrniv:10: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n  from pkg_resources import working_set\n/opt/anaconda3/envs/hc12/bin/nrniv:10: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n  from pkg_resources import working_set\nnumprocs=2\nLoading custom mechanism files from /Users/austinsoplata/rep/brn/hnn-core/hnn_core/mod/arm64/.libs/libnrnmech.so\nBuilding the NEURON model\nLoading custom mechanism files from /Users/austinsoplata/rep/brn/hnn-core/hnn_core/mod/arm64/.libs/libnrnmech.so\n[Done]\nTrial 1: 0.03 ms...\nTrial 1: 10.0 ms...\nTrial 1: 20.0 ms...\nTrial 1: 30.0 ms...\nTrial 1: 40.0 ms...\nTrial 1: 50.0 ms...\nTrial 1: 60.0 ms...\nTrial 1: 70.0 ms...\nTrial 1: 80.0 ms...\nTrial 1: 90.0 ms...\nTrial 1: 100.0 ms...\nTrial 1: 110.0 ms...\nTrial 1: 120.0 ms...\nTrial 1: 130.0 ms...\nTrial 1: 140.0 ms...\nTrial 1: 150.0 ms...\nTrial 1: 160.0 ms...\nTrial 1: 170.0 ms...\nTrial 1: 180.0 ms...\nTrial 1: 190.0 ms...\nTrial 1: 200.0 ms...\nTrial 1: 210.0 ms...\nTrial 1: 220.0 ms...\nTrial 1: 230.0 ms...\nTrial 1: 240.0 ms...\nTrial 1: 250.0 ms...\nTrial 1: 260.0 ms...\nTrial 1: 270.0 ms...\nTrial 1: 280.0 ms...\nTrial 1: 290.0 ms...\nTrial 1: 300.0 ms...\n\n        &lt;Figure size 640x480 with 1 Axes&gt;\n    </div>\n</div>\n<div class='output-cell'>\n    <img src='output_nb_use_mpi_backend_for_parallelization_notebook/fig_01.png'/>\n</div>"
        }
    }
}